{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Punjhk9YVJx5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "data = pd.read_csv(r\"D:\\ML\\emotions.csv\", encoding ='latin-1')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nltk.download('stopwords')\n",
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))\n",
        "\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text=\" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text=\" \".join(text)\n",
        "    return text\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(clean)"
      ],
      "metadata": {
        "id": "_B-Hz6JgV8Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sentiments = SentimentIntensityAnalyzer()\n",
        "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"tweet\"]]\n",
        "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"tweet\"]]\n",
        "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"tweet\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtiY83dRXvZp",
        "outputId": "186818c3-9373-4922-b1a9-9849f7fbba8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"tweet\", \"Positive\",\n",
        "             \"Negative\", \"Neutral\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU5DAQXVa8RG",
        "outputId": "b37fd1ad-fecb-49bb-8740-34a7ebb2e67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  Positive  Negative  \\\n",
            "0   rt mayasolov woman shouldnt complain clean ho...     0.147     0.157   \n",
            "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...     0.000     0.280   \n",
            "2   rt urkindofbrand dawg rt  ever fuck bitch sta...     0.000     0.577   \n",
            "3              rt cganderson vivaba look like tranni     0.333     0.000   \n",
            "4   rt shenikarobert shit hear might true might f...     0.154     0.407   \n",
            "\n",
            "   Neutral  \n",
            "0    0.696  \n",
            "1    0.720  \n",
            "2    0.423  \n",
            "3    0.667  \n",
            "4    0.440  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sum(data[\"Positive\"])\n",
        "y = sum(data[\"Negative\"])\n",
        "z = sum(data[\"Neutral\"])\n",
        "\n",
        "def sentiment_score(a, b, c):\n",
        "    if (a>b) and (a>c):\n",
        "        print(\"Positive ðŸ˜Š \")\n",
        "    elif (b>a) and (b>c):\n",
        "        print(\"Negative ðŸ˜  \")\n",
        "    else:\n",
        "        print(\"Neutral ðŸ™‚ \")\n",
        "sentiment_score(x, y, z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2d8IKbKbGEv",
        "outputId": "5db76d41-7a9a-4d65-f3bb-279a57ae3d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral ðŸ™‚ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Positive: \", x)\n",
        "print(\"Negative: \", y)\n",
        "print(\"Neutral: \", z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAkcOANybSH_",
        "outputId": "367b66c8-e0f8-4bb6-e125-7af66d1ae003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive:  2895.4580000000074\n",
            "Negative:  7234.598999999926\n",
            "Neutral:  14647.936999999725\n"
          ]
        }
      ]
    }
  ]
}